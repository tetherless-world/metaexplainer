'''
Run RAG on outputs from explainer methods with prompts for identified explanation type from EO
Base it off of: https://towardsai.net/p/machine-learning/query-your-dataframes-with-powerful-large-language-models-using-langchain
Or https://docs.llamaindex.ai/en/stable/examples/query_engine/pandas_query_engine/
'''

import logging
import sys
from IPython.display import Markdown, display

import pandas as pd
from llama_index.experimental.query_engine import PandasQueryEngine

from langchain.agents.agent_types import AgentType
from langchain_experimental.agents.agent_toolkits import create_pandas_dataframe_agent
from langchain_openai import OpenAI

import sys
sys.path.append('../')

from metaexplainercode import metaexplainer_utils
from metaexplainercode import codeconstants
from metaexplainercode import ontology_utils

logging.basicConfig(stream=sys.stdout, level=logging.INFO)
logging.getLogger().addHandler(logging.StreamHandler(stream=sys.stdout))

from jinja2 import Template

def construct_prompt_record(output_folder):
	dir_ep = output_folder.split('/')[-1]
	sub_dirs = delegate_output_folders[output_folder]

	record_dets = metaexplainer_utils.read_delegate_records_df(output_folder + '/record.csv')

	prompt_record = {}

	prompt_record['Explanation_Type'] = record_dets.iloc[0]['Explanation type']
	prompt_record['Definition'] = explanation_definition_pd[explanation_definition_pd['Explanation type'] == prompt_record['Explanation_Type']]['Definition'].item()
	prompt_record['Explainer_Method'] = dir_ep.split('_')[2]
	prompt_record['Modality'] = explainer_modality_pd[explainer_modality_pd['Instances'].str.lower() == prompt_record['Explainer_Method']]['Modality'].item()
	prompt_record['Question'] = record_dets['Question'].item()
	prompt_record['feature_groups'] = eval(record_dets['Feature groups'].item())

	results_list = []
	evaluations_list = []
	subset_list = []

	for sub_dir in sub_dirs:
		results_list.append(pd.read_csv(sub_dir + '/Results.csv'))
		evaluations_list.append(pd.read_csv(sub_dir + '/Evaluations.csv'))
		subset_list.append(pd.read_csv(sub_dir + '/Subset.csv'))
		
	evaluations_df = pd.concat([x.head(10) for x in evaluations_list], ignore_index=True)

	grouped_mean = evaluations_df.groupby('Metric')['Value'].mean().reset_index()

		# Renaming the columns for better readability
	grouped_mean.columns = ['Metric', 'mean_value']

	prompt_record['Metrics'] = grouped_mean
	prompt_record['Results'] = results_list
	prompt_record['Subsets'] = subset_list

	return prompt_record

def retrieve_prompt_subset():
	prompt_template_text = '''
	Find a match in the data based on {{Question}}. If there are no full matches, summarize the dataset.'''
	# Also, keep in mind the contexts that:
	# {{Question}} is addressed by a {{Explanation_Type}}
	# Explanations of {{Explanation_Type}} typically have a format of {{Definition}} and are answered in {{Modality}}, so try recreating this.
	# There are several dataframes in the answer that answer the feature groups identified:
	# {%- for group in feature_groups %}
	# {{group}} \n
	# {%- endfor %}
	# Results were generated by {{Explainer_Method}}.
	# '''
	return prompt_template_text


def retrieve_prompt_explanation():
	#certain kind of prediction and features in certain ways, and that fact that it uses confidence 
	prompt_template_text = '''
	Summarize the data in English based on {{Definition}}.'''
	# Also, keep in mind the contexts that:
	# {{Question}} is addressed by a {{Explanation_Type}}
	# Explanations of {{Explanation_Type}} typically have a format of {{Definition}} and are answered in {{Modality}}, so try recreating this.
	# There are several dataframes in the answer that answer the feature groups identified:
	# {%- for group in feature_groups %}
	# {{group}} \n
	# {%- endfor %}
	# Results were generated by {{Explainer_Method}}.
	# '''

	# and have:
	# {%- for metric in Metrics %}
	# {{metric['Metric']}} {{metric['mean_value']}} \n
	# {%- endfor %}

	return prompt_template_text

if __name__=='__main__':
	'''
	Pass into prompt:
	- EO template
	- Metrics 
	- Question 
	- Modality 
	Dataframes (all will have same columns so that is good):
	- Explainer results
	'''
	delegate_output_folders = metaexplainer_utils.read_delegate_explainer_outputs()

	explainer_modality_pd = pd.read_csv(codeconstants.DELEGATE_FOLDER + '/explanation_type_methods.csv')
	explanation_definition_pd = pd.read_csv(codeconstants.SYNTHESIS_FOLDER + '/explanation_type_definition.csv')

	prompt_template_text_explan = retrieve_prompt_explanation()
	prompt_subset = retrieve_prompt_subset()

	
	prompt_template = Template(prompt_template_text_explan)
	prompt_template_subset = Template(prompt_subset)

	for output_folder in delegate_output_folders.keys():
		prompt_record = construct_prompt_record(output_folder)

		filled_prompt = prompt_template.render(prompt_record)
		filled_prompt_subset = prompt_template_subset.render(prompt_record)

		print(prompt_record)

		query_engine = PandasQueryEngine(df=prompt_record['Subsets'][0], verbose=False, synthesize_response=True)
	
		# #need to replace this query with EO templates - check how to add the templates
		response = query_engine.query(
			filled_prompt_subset,
		)
		print('Subset match:', response)

		query_engine_explan = PandasQueryEngine(df=prompt_record['Results'][0], verbose=False, synthesize_response=True)
		response_explan = query_engine_explan.query(
			filled_prompt
		)
		print('Summary of results',response_explan)

		# langchain_agent_subsets = create_pandas_dataframe_agent(OpenAI(temperature=0, seed=3), prompt_record['Subsets'], max_iterations = 50, verbose=True)
		# out = langchain_agent_subsets.invoke(filled_prompt_subset)
		# print('Subsets', out)

		# langchain_agent = create_pandas_dataframe_agent(OpenAI(temperature=0, seed=3), prompt_record['Results'], max_iterations = 50, verbose=True)
		# out = langchain_agent.invoke(filled_prompt)
		# print('Summary of results',out)
		

	# df = pd.DataFrame(
	# {
	# 	"city": ["Toronto", "Tokyo", "Berlin"],
	# 	"population": [2930000, 13960000, 3645000],
	# })
	# df1 = pd.DataFrame(
	# 	{
	# 		"city": ["Bangalore", "Bombay", "Berlin"],
	# 	"population": [2930000, 13960000, 3645000],
	# 	}
	# )
	
	# query_city = "Answer question: What are the cities with the highest population? Give both the city and population? "\
	# 		"Structure of response: Answer in natural-language inlcuding details of what value addresses the question."

	# langchain_agent = create_pandas_dataframe_agent(OpenAI(temperature=0), [df, df1], verbose=False)
	# out = langchain_agent.invoke(query_city)
	# print(out)

	


