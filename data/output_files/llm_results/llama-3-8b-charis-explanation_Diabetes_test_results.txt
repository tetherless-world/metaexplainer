---Confusion matrix for explanation types--- 
                            precision    recall  f1-score   support

    Contextual Explanation       0.50      0.67      0.57         6
          Data Explanation       0.80      0.62      0.70        13
   Contrastive Explanation       0.00      0.00      0.00         5
    Case Based Explanation       0.50      0.07      0.12        14
     Rationale Explanation       0.69      0.92      0.79        12
Counterfactual Explanation       0.50      1.00      0.67         3

                 micro avg       0.60      0.51      0.55        53
                 macro avg       0.50      0.55      0.47        53
              weighted avg       0.57      0.51      0.48        53

F1 Exact Match scores on text fields: 

			
Machine interpretation, F1: 59.06%, Precision: 55.91% and Recall: 62.58%
		
			
Action, F1: 57.48%, Precision: 50.0% and Recall: 67.6%
		
			
Likelihood, F1: 81.46%, Precision: 84.34% and Recall: 78.77%
		
---F1 Levenshtein scores on text fields---

			
Machine interpretation, F1: 18.87%, Precision: 18.87% and Recall: 18.87%
		
			
Action, F1: 19.23%, Precision: 19.61% and Recall: 18.87%
		
			
Likelihood, F1: 81.13%, Precision: 81.13% and Recall: 81.13%
		
---Exact match on text fields---

Machine interpretation, Exact match: 29.53%
Action, Exact match: 28.74%
Likelihood, Exact match: 40.73%

---Errors---
Non-matches between result and input []
These will be skipped.