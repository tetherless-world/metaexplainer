---Confusion matrix for explanation types--- 
                            precision    recall  f1-score   support

     Rationale Explanation       0.59      0.88      0.71        25
          Data Explanation       0.62      0.78      0.69        40
    Case Based Explanation       0.36      0.64      0.46        25
   Contrastive Explanation       0.71      0.89      0.79        19
Counterfactual Explanation       0.60      0.92      0.73        13
    Contextual Explanation       0.65      0.65      0.65        17

                 micro avg       0.56      0.78      0.66       139
                 macro avg       0.59      0.79      0.67       139
              weighted avg       0.58      0.78      0.66       139

F1 Exact Match scores on text fields: 

			
Machine interpretation, F1: 45.31%, Precision: 64.68% and Recall: 34.87%
		
			
Action, F1: 72.85%, Precision: 70.42% and Recall: 75.46%
		
			
Likelihood, F1: 80.03%, Precision: 83.22% and Recall: 77.07%
		
---F1 Levenshtein scores on text fields---

			
Machine interpretation, F1: 17.62%, Precision: 17.62% and Recall: 17.62%
		
			
Action, F1: 28.73%, Precision: 30.77% and Recall: 26.94%
		
			
Likelihood, F1: 77.2%, Precision: 77.2% and Recall: 77.2%
		
---Exact match on text fields---

Machine interpretation, Exact match: 22.66%
Action, Exact match: 36.43%
Likelihood, Exact match: 40.01%

---Errors---
Non-matches between result and input []
These will be skipped.