---Confusion matrix for explanation types--- 
                            precision    recall  f1-score   support

    Contextual Explanation       0.00      0.00      0.00         6
          Data Explanation       0.62      0.38      0.48        13
   Contrastive Explanation       1.00      0.20      0.33         5
    Case Based Explanation       1.00      0.14      0.25        14
     Rationale Explanation       1.00      0.17      0.29        12
Counterfactual Explanation       1.00      0.67      0.80         3

                 micro avg       0.71      0.23      0.34        53
                 macro avg       0.77      0.26      0.36        53
              weighted avg       0.79      0.23      0.32        53

F1 Exact Match scores on text fields: 

			
Machine interpretation, F1: 45.81%, Precision: 61.2% and Recall: 36.6%
		
			
Action, F1: 54.19%, Precision: 61.5% and Recall: 48.43%
		
			
Likelihood, F1: 41.74%, Precision: 61.47% and Recall: 31.6%
		
---F1 Levenshtein scores on text fields---

			
Machine interpretation, F1: 11.32%, Precision: 11.32% and Recall: 11.32%
		
			
Action, F1: 6.45%, Precision: 7.5% and Recall: 5.66%
		
			
Likelihood, F1: 33.96%, Precision: 33.96% and Recall: 33.96%
		
---Exact match on text fields---

Machine interpretation, Exact match: 22.9%
Action, Exact match: 27.1%
Likelihood, Exact match: 20.87%

---Errors---
Non-matches between result and input []
These will be skipped.